{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cb49401-0f33-4ff0-9232-764d281a44c5",
   "metadata": {},
   "source": [
    "## Expanding the Use of Satellite Imagery with Machine Learning  \n",
    "Author: Nikolay Zhechev  \n",
    "Date: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae23437-9407-4d0c-a1c7-64c03e66b6b5",
   "metadata": {},
   "source": [
    "#### Abstract  \n",
    "\n",
    "Satellite imagery provides a unique view of planet Earth and a possibility to see features that were never seeen before. In recent years satellite imagery has become even more essential. Now we are able to see astonishing viwes in detail, narowing to just a few meters.  \n",
    "Collected images have multiple purposes from commmercial and educational to the ability to provide insights on how our Earth is evolving and changing. One of the most fascinating aspects of Earth imagery is that we are able to destinguish meanighful patterns over time helping us with predictions and future outcome. Today humanity has millions of images increasing with around 80TB/day from the past few decades which can help shape our future. Two considerations arise: vast amounts of data and a reproducible method to perfom predictions. Machine Learning can solve both, providing a reproducible and structured way of detecting patterns and important features of sattelite imagery, enabling indepth model selection and tuning for all specific needs. Exporting of sattelite image data and what are good, approachable tecniques and how this data can be fed to a machine learning model to evaluate results, outcomes and determine improvements, reproducibility and further steps.\n",
    "The text aims to further expand the knowledge of the reader and solidify a good understanding of how machine learning concepts can be applyed to sattelite imagery. Both machine learning and specific satellite imagery concepts will be looked at in more detail.\n",
    "\n",
    "#### Indroduction  \n",
    "Manual investigation of sattelite imagery can be very time consuming as well as very difficult. Specific software, land and map understanding is required. How can this process be made more efficient? What further value can be generated from a more streamline and effective processing method? The use of machine learning algorithms can solve most of our questions. It should provide a good and stable process of image predictions, pattern recognition and much more.\n",
    "\n",
    "> from: https://journalofbigdata.springeropen.com/articles/10.1186/s40537-023-00772-x  \n",
    "In recent times, Deep Learning, a sophisticated tool in the field of machine learning, has demonstrated its effectiveness in the realm of computer vision and subsequently, in remote sensing as well. The conventional machine learning tools such as Support Vector Machine (SVM) and Random Forest (RF) which are shallow-structured, have major limitations that are addressed by these advanced machine learning algorithms. Prominent deep learning models such as Deep Belief Net (DBN), Stacked Auto-Encoder (SAE), and deep Convolutional Neural Network (CNN) have shown promising results in several remote sensing applications, including segmentation, object detection, and classification. These models are characterized by deep architecture, multi-layered interconnected channels, and a high capacity to learn features.  \n",
    "Nonetheless, the application of these transformers is computationally expensive, and their efficiency decreases exponentially with the size of the image, thereby requiring significant computational resources.\n",
    "\n",
    "Presented in this text are approaches with CNN and SVM. Both methods are used with diiferent datasets to attempt and understand how results differ with data and how these models work and interpret data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0dda76-130e-46eb-8807-9e3b994a93c2",
   "metadata": {},
   "source": [
    "Some use cases include:\n",
    "- agriculture, forestry, and sustainability sectors;\n",
    "- understand local waterway pollution, illegal land uses, or mass migrations;\n",
    "- predict wilwdefire and flood;\n",
    "- predict glacier and water differences;\n",
    "- crops and food predictions;\n",
    "- poverty prediction;\n",
    "- infrastructure and urban planning;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b696c4-0a7e-4690-a801-27353d563e7a",
   "metadata": {},
   "source": [
    "Spatial Resolution: how many meters are covered per pixel, higher resolution will unlock some use cases and give better performance for most algorithms.\n",
    "\n",
    "Instruments available: the instruments will capture different spectral bands, both from the visible and invisible spectrum. Bands usefulness will vary depending on the use case.\n",
    "\n",
    "Temporal resolution : time between two visits on a given spot on earth. Note that many satellite systems actually include several satellites and in that case the global temporal resolution is usually equal to that of one of its satellites divided by the number of satellites.\n",
    "\n",
    "Radiometric resolution : the number of possible values the instrument captures. The higher, the more precise the measurements are.\n",
    "\n",
    "![image.png](attachment:a87e6082-68ee-4ab8-9f3a-677dee3d4e35.png)\n",
    "\n",
    "![Steps](https://miro.medium.com/v2/resize:fit:4800/format:webp/1*tVmF_DrmDwqws0CTLe3Vuw.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88af872-edf6-4e15-958b-e6763b81db05",
   "metadata": {},
   "source": [
    "Spectral, temporal, and spatial resolution are major features of remote sensing images and are important parameters to be considered during remote sensing image classification process;\n",
    "\n",
    "1.\n",
    "Spectral resolution is composed of different wavelengths of electromagnetic radiation.\n",
    "\n",
    "2.\n",
    "Temporal resolution is the time interval between image acquisitions.\n",
    "\n",
    "3.\n",
    "Spatial resolution is the size of a pixel on the ground. These parameters play a critical role in identifying different land cover types and monitoring changes in land cover over time.\n",
    "\n",
    "They are complex features on remote sensing images and efficient system must be able to effectively process them to achieve accurate classification of remote sensing images by focusing on spectral, temporal, and spatial resolution of the images.\n",
    "\n",
    "There are also other types of remote sensing images based on the nature of the capturing devices. These are categorised into optical, thermal, hyper-spectral, and SAR images:\n",
    "\n",
    "1.\n",
    "Optical images capture visible and near-infrared regions of the electromagnetic spectrum and are the most commonly used remote sensing data for land cover classification.\n",
    "\n",
    "2.\n",
    "Thermal images capture the thermal radiation emitted by the Earth‚Äôs surface and is used to detect temperature variations.\n",
    "\n",
    "3.\n",
    "Hyper-spectral images capture a wide range of spectral bands with narrow bandwidths, allowing for the identification of more subtle spectral signatures.\n",
    "\n",
    "4.\n",
    "SAR images use microwave radiation and can penetrate through clouds and vegetation, making them useful in detecting changes in surface features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce84d8b-4edb-4413-807a-6d099104bd34",
   "metadata": {},
   "source": [
    "## *Method and materials section - plus code example (reproducibility?) >\n",
    "\n",
    "Let‚Äôs assume you want to train a machine learning model to identify objects in an image it‚Äôs never encountered. The first step in training this supervised machine learning model is to annotate and label a collection of images, called a training dataset. Annotation involves manually identifying and marking the regions of interest in an image.\n",
    "\n",
    "For example, we would annotate each image by outlining what is present in the image and assigning them the corresponding class label. This annotated dataset becomes the foundation for training the model. Once the training dataset is labeled, relevant features need to be extracted from the images. Feature extraction involves identifying and capturing important characteristics or patterns that distinguish one class from another.\n",
    "\n",
    "\n",
    "\n",
    "There are various techniques available for feature extraction in image processing, ranging from simple methods like color histograms and texture descriptors to more advanced approaches like convolutional neural networks (CNNs).\n",
    "\n",
    "The training process of a supervised ML model, like a CNN, involves several steps. First, the data needs to be preprocessed to ensure consistency and quality. This may involve resizing the images, normalizing pixel values, and augmenting the dataset by applying transformations like rotations or flips to increase its diversity.\n",
    "\n",
    "\n",
    "\n",
    "CNNs‚Äô architecture tries to mimic the structure of neurons in the human visual system composed of multiple layers, where each one is responsible for detecting a specific feature in the data.  As illustrated in the image below, the typical CNN is made of a combination of four main layers: \n",
    "\n",
    "- Convolutional layers  \n",
    "- Rectified Linear Unit (ReLU for short)  \n",
    "- Pooling layers  \n",
    "- Fully connected layersÔøΩùëíùëë . "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b102023a-a0bd-4479-a9d9-7013e0008a1a",
   "metadata": {},
   "source": [
    "Spectral indices, which are features computed from two or\n",
    "more spectral bands, are commonly used in place of or to\n",
    "supplement the bands. The most commonly used index is the\n",
    "normalized difference vegetation index (NDVI), which\n",
    "compares the values of the red and near-infrared (NIR) band\n",
    "using this formula:  \n",
    "\n",
    "$ NDVI = \\frac{(NIR‚àíRED)}{(NIR+RED)} $\n",
    "\n",
    "NDVI quantifies vegetation by measuring the difference between near-infrared (which vegetation strongly reflects) and red light (which vegetation absorbs)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af04d37-ccf5-4fe0-b2e1-d2b20d16b701",
   "metadata": {},
   "source": [
    "Unsupervised learning does not rely on labeled data but instead aims to discover hidden patterns, structures, or relationships within the data itself.\n",
    "\n",
    "The purpose of unsupervised learning in image analysis is to uncover meaningful structures and insights from unlabeled image data. By utilizing unsupervised learning techniques, valuable information can be extracted and a deeper understanding is gained of the underlying characteristics of images.\n",
    "\n",
    "Unsupervised learning can help identify clusters of similar images, discover patterns or textures that are characteristic of certain image classes, and detect anomalies or outliers within the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a8d17f-b837-45ad-ab25-e96bb323829b",
   "metadata": {},
   "source": [
    "## *Results and further discussion - model results, interpretation >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18222b2-b87e-47a5-8fd8-9822f4d35e9e",
   "metadata": {},
   "source": [
    "## *Conclusion - outcome>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d464e359-a0d8-4156-845a-21b5957236a9",
   "metadata": {},
   "source": [
    "## *Cite and resources >"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
